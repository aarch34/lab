!pip install tensorflow numpy
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Embedding, Dense
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences


source_sentences = ['hello', 'how are you', 'good morning']
target_sentences = ['hola', 'cómo estás', 'buenos días']  


target_sentences_input = ['<start> ' + sentence for sentence in target_sentences]
target_sentences_output = [sentence + ' <end>' for sentence in target_sentences]


def tokenize(sentences):
    tokenizer = Tokenizer(filters='')
    tokenizer.fit_on_texts(sentences)
    tensor = tokenizer.texts_to_sequences(sentences)
    tensor = pad_sequences(tensor, padding='post')
    return tensor, tokenizer

source_tensor, source_tokenizer = tokenize(source_sentences)
target_input_tensor, target_tokenizer = tokenize(target_sentences_input)
target_output_tensor, _ = tokenize(target_sentences_output)

source_vocab_size = len(source_tokenizer.word_index) + 1
target_vocab_size = len(target_tokenizer.word_index) + 1

embedding_dim = 256
units = 512


encoder_inputs = Input(shape=(None,))
enc_emb = Embedding(source_vocab_size, embedding_dim)(encoder_inputs)
encoder_lstm = LSTM(units, return_state=True)
encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)
encoder_states = [state_h, state_c]

decoder_inputs = Input(shape=(None,))
dec_emb_layer = Embedding(target_vocab_size, embedding_dim)
dec_emb = dec_emb_layer(decoder_inputs)
decoder_lstm = LSTM(units, return_sequences=True, return_state=True)
decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)
decoder_dense = Dense(target_vocab_size, activation='softmax')
decoder_outputs = decoder_dense(decoder_outputs)


model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()


model.fit([source_tensor, target_input_tensor],np.expand_dims(target_output_tensor, -1),batch_size=2,epochs=100)
